{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bq-IHSrRPYjc"
   },
   "source": "# Asynchronous Inference with Ray Serve\n\n**⏱️ Time to complete:** 30 minutes\n\nThis template demonstrates how to build scalable asynchronous inference services using Ray Serve. Learn how to handle long-running PDF processing tasks without blocking HTTP responses, using Celery task queues and Redis as a message broker."
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qBGu_yjLPYje"
   },
   "source": [
    "## Overview\n",
    "\n",
    "Traditional synchronous APIs block until processing completes, causing timeouts for long-running tasks. Ray Serve's asynchronous inference pattern decouples request lifetime from compute time by:\n",
    "\n",
    "1. Accepting HTTP requests and immediately returning a task ID\n",
    "2. Enqueuing work to background processors (Celery workers)\n",
    "3. Allowing clients to poll for status and retrieve results\n",
    "\n",
    "This example implements a **PDF processing service** that extracts text and generates summaries from PDF documents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rXwBYDRWPYjh"
   },
   "source": [
    "## Architecture Overview\n",
    "\n",
    "```\n",
    "┌─────────────┐\n",
    "│   Client    │\n",
    "└──────┬──────┘\n",
    "       │ HTTP POST /process\n",
    "       ▼\n",
    "┌─────────────────────┐\n",
    "│   AsyncPDFAPI       │ ← Ingress Deployment\n",
    "│ (HTTP Endpoints)    │\n",
    "└──────┬──────────────┘\n",
    "       │ enqueue_task()\n",
    "       ▼\n",
    "┌─────────────────────┐\n",
    "│   Redis Queue       │ ← Message Broker\n",
    "│ (Celery Backend)    │\n",
    "└──────┬──────────────┘\n",
    "       │ consume tasks\n",
    "       ▼\n",
    "┌─────────────────────┐\n",
    "│   PDFProcessor      │ ← Task Consumer Deployment\n",
    "│ @task_consumer      │   (Scaled to N replicas)\n",
    "│ - process_pdf       │\n",
    "└─────────────────────┘\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mUj7ohuhPYje"
   },
   "source": [
    "## Prerequisites\n",
    "\n",
    "- Python 3.9+\n",
    "- Ray 2.50.0+\n",
    "- Redis (for message broker and result backend)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D8O5Bk2gPYje"
   },
   "source": "## Step 1: Setup Redis\n\nRedis serves as both the message broker (task queue) and result backend.\n\n**Install and start Redis (Google Colab compatible):**"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "Zsr4HD0_PYje",
    "outputId": "3ecc8fe0-5a73-4793-8735-d2517d38c82d"
   },
   "outputs": [],
   "source": [
    "# Install and start Redis server\n",
    "!sudo apt-get update -qq\n",
    "!sudo apt-get install -y redis-server\n",
    "!redis-server --port 6399 --save \"\" --appendonly no --daemonize yes\n",
    "\n",
    "# Verify Redis is running\n",
    "!redis-cli -p 6399 ping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JzPQjYzmPYjf"
   },
   "source": "**Alternative methods:**\n\n- **macOS:** `brew install redis && brew services start redis`\n- **Docker:** `docker run -d -p 6379:6379 redis:latest`\n- **Other platforms:** [Official Redis Installation Guide](https://redis.io/docs/getting-started/installation/)"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jJ6ahzMPPYjf"
   },
   "source": [
    "## Step 2: Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2KQe0ROXPYjf"
   },
   "outputs": [],
   "source": [
    "!pip install -q ray[serve-async-inference]>=2.50.0 requests>=2.31.0 PyPDF2>=3.0.0 celery[redis]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sqLdlKIhPYjf"
   },
   "source": "## Step 3: Start the Ray Serve Application\n\nLet's see and run the code for the service. We will go through each component independently."
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### 3.1 Ingress Deployment to Handle HTTP Requests\n\nThe `AsyncPDFAPI` deployment handles HTTP requests and enqueues tasks."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from fastapi import FastAPI\n",
    "from pydantic import BaseModel, HttpUrl\n",
    "from ray import serve\n",
    "from ray.serve.handle import DeploymentHandle\n",
    "from ray.serve.schema import TaskProcessorConfig\n",
    "from ray.serve.task_consumer import instantiate_adapter_from_config\n",
    "\n",
    "fastapi_app = FastAPI(title=\"Async PDF Processing API\")\n",
    "logger = logging.getLogger(\"ray.serve\")\n",
    "\n",
    "@serve.deployment(ray_actor_options={\"num_cpus\": 0.1})\n",
    "@serve.ingress(fastapi_app)\n",
    "class AsyncPDFAPI:\n",
    "    \"\"\"\n",
    "    HTTP API for submitting and checking PDF processing tasks.\n",
    "\n",
    "    Endpoints:\n",
    "    - POST /process: Submit a PDF processing task\n",
    "    - GET /status/{task_id}: Check task status and get results\n",
    "    \"\"\"\n",
    "\n",
    "    class ProcessPDFRequest(BaseModel):\n",
    "        \"\"\"Request schema for PDF processing.\"\"\"\n",
    "        pdf_url: HttpUrl\n",
    "        max_summary_paragraphs: int = 3\n",
    "\n",
    "    def __init__(self, task_processor_config: TaskProcessorConfig, handler: DeploymentHandle):\n",
    "        \"\"\"Initialize the API with task adapter.\"\"\"\n",
    "        self.adapter = instantiate_adapter_from_config(task_processor_config)\n",
    "        logger.info(\"AsyncPDFAPI initialized\")\n",
    "\n",
    "    @fastapi_app.post(\"/process\")\n",
    "    async def process_pdf(self, request: ProcessPDFRequest):\n",
    "        \"\"\"\n",
    "        Submit a PDF processing task.\n",
    "\n",
    "        Returns task_id immediately without waiting for processing to complete.\n",
    "        Client should poll /status/{task_id} to check progress.\n",
    "        \"\"\"\n",
    "        task_result = self.adapter.enqueue_task_sync(\n",
    "            task_name=\"process_pdf\",\n",
    "            kwargs={\n",
    "                \"pdf_url\": str(request.pdf_url),\n",
    "                \"max_summary_paragraphs\": request.max_summary_paragraphs,\n",
    "            },\n",
    "        )\n",
    "\n",
    "        logger.info(f\"Enqueued task: {task_result}\")\n",
    "\n",
    "        return {\n",
    "            \"task_id\": task_result.id,\n",
    "            \"status\": task_result.status,\n",
    "            \"message\": \"PDF processing task submitted successfully\",\n",
    "        }\n",
    "\n",
    "    @fastapi_app.get(\"/status/{task_id}\")\n",
    "    async def get_status(self, task_id: str):\n",
    "        \"\"\"\n",
    "        Get task status and results.\n",
    "\n",
    "        Status values:\n",
    "        - PENDING: Task queued, waiting for worker\n",
    "        - STARTED: Worker is processing the task\n",
    "        - SUCCESS: Task completed successfully (result available)\n",
    "        - FAILURE: Task failed (error message available)\n",
    "        \"\"\"\n",
    "        status = self.adapter.get_task_status_sync(task_id)\n",
    "\n",
    "        return {\n",
    "            \"task_id\": task_id,\n",
    "            \"status\": status.status,\n",
    "            \"result\": status.result if status.status == \"SUCCESS\" else None,\n",
    "            \"error\": str(status.result) if status.status == \"FAILURE\" else None,\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "**Key points:**\n\n- `/process` endpoint enqueues tasks and returns immediately with a task ID\n- `/status/{task_id}` endpoint polls Redis to check task status\n- No blocking - responses are instant regardless of processing time"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### 3.2 Create the Task Consumer Deployment\n\nNow, below is the deployment consumer code, which will read from the task queue and implement the tasks.\n\n**What's a Task Consumer?**\n\nThe `@task_consumer` decorator transforms a Ray Serve deployment into a worker that consumes tasks from a queue. Ray Serve automatically scales these workers based on queue depth.\n\n**What's a Task Handler?**\n\nThe `@task_handler` decorator registers a method to process a specific task type. Each handler corresponds to a task name that producers use when enqueuing work.\n\nFor more details, see the [Asynchronous Inference Guide](https://docs.ray.io/en/master/serve/asynchronous-inference.html)."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import time\n",
    "from typing import Dict, Any\n",
    "import requests\n",
    "from PyPDF2 import PdfReader\n",
    "from ray import serve\n",
    "from ray.serve.schema import CeleryAdapterConfig, TaskProcessorConfig\n",
    "from ray.serve.task_consumer import (\n",
    "    task_consumer,\n",
    "    task_handler,\n",
    ")\n",
    "\n",
    "TASK_PROCESSOR_CONFIG = TaskProcessorConfig(\n",
    "    queue_name=\"pdf_processing_queue\",\n",
    "    adapter_config=CeleryAdapterConfig(\n",
    "        broker_url=\"redis://127.0.0.1:6399/0\",\n",
    "        backend_url=\"redis://127.0.0.1:6399/0\",\n",
    "    ),\n",
    "    max_retries=3,\n",
    "    failed_task_queue_name=\"failed_pdfs\",\n",
    "    unprocessable_task_queue_name=\"invalid_pdfs\",\n",
    ")\n",
    "\n",
    "@serve.deployment(num_replicas=2, max_ongoing_requests=5, ray_actor_options={\"num_cpus\": 0.1})\n",
    "@task_consumer(task_processor_config=TASK_PROCESSOR_CONFIG)\n",
    "class PDFProcessor:\n",
    "    \"\"\"\n",
    "    Background worker that processes PDF documents asynchronously.\n",
    "\n",
    "    Configuration:\n",
    "    - num_replicas=2: Run 2 worker instances\n",
    "    - max_ongoing_requests=5: Each worker handles up to 5 concurrent tasks\n",
    "    - max_retries=3: Retry failed tasks up to 3 times\n",
    "    \"\"\"\n",
    "\n",
    "    @task_handler(name=\"process_pdf\")\n",
    "    def process_pdf(\n",
    "        self, pdf_url: str, max_summary_paragraphs: int = 3\n",
    "    ) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Download PDF, extract text, and generate summary.\n",
    "        \"\"\"\n",
    "        start_time = time.time()\n",
    "        logger.info(f\"Processing PDF: {pdf_url}\")\n",
    "\n",
    "        try:\n",
    "            # Download PDF from URL\n",
    "            response = requests.get(pdf_url, timeout=30)\n",
    "            response.raise_for_status()\n",
    "\n",
    "            # Parse PDF content\n",
    "            pdf_file = io.BytesIO(response.content)\n",
    "            try:\n",
    "                pdf_reader = PdfReader(pdf_file)\n",
    "            except Exception as e:\n",
    "                raise ValueError(f\"Invalid PDF file: {str(e)}\")\n",
    "\n",
    "            if len(pdf_reader.pages) == 0:\n",
    "                raise ValueError(\"PDF contains no pages\")\n",
    "\n",
    "            # Extract text from all pages\n",
    "            full_text = \"\"\n",
    "            for page in pdf_reader.pages:\n",
    "                text = page.extract_text()\n",
    "                if text:\n",
    "                    full_text += text + \"\\n\"\n",
    "\n",
    "            if not full_text.strip():\n",
    "                raise ValueError(\"PDF contains no extractable text\")\n",
    "\n",
    "            # Generate summary (first N paragraphs)\n",
    "            paragraphs = [p.strip() for p in full_text.split(\"\\n\\n\") if p.strip()]\n",
    "            summary = \"\\n\\n\".join(paragraphs[:max_summary_paragraphs])\n",
    "\n",
    "            # Calculate metadata\n",
    "            result = {\n",
    "                \"status\": \"success\",\n",
    "                \"pdf_url\": pdf_url,\n",
    "                \"page_count\": len(pdf_reader.pages),\n",
    "                \"word_count\": len(full_text.split()),\n",
    "                \"full_text\": full_text,\n",
    "                \"summary\": summary,\n",
    "                \"processing_time_seconds\": round(time.time() - start_time, 2),\n",
    "            }\n",
    "\n",
    "            logger.info(f\"Processed PDF: {result['page_count']} pages, {result['word_count']} words\")\n",
    "            return result\n",
    "\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            error_msg = f\"Failed to download PDF: {str(e)}\"\n",
    "            logger.error(error_msg)\n",
    "            raise ValueError(error_msg)\n",
    "        except Exception as e:\n",
    "            error_msg = f\"Failed to process PDF: {str(e)}\"\n",
    "            logger.error(error_msg)\n",
    "            raise ValueError(error_msg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "**Key points:**\n\n- `num_replicas=2` scales to 2 worker instances for parallel processing\n- The consumer automatically polls the queue and processes tasks\n- Failed tasks retry up to `max_retries` times before moving to the dead letter queue"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### 3.3 Bind Deployments into an Application\n\nNow, we will combine the deployments and run the application."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iK24ZGxXgpy4"
   },
   "outputs": [],
   "source": [
    "consumer = PDFProcessor.bind()\n",
    "\n",
    "app = AsyncPDFAPI.bind(task_processor_config=TASK_PROCESSOR_CONFIG, handler=consumer)\n",
    "\n",
    "serve.run(\n",
    "    target=app,\n",
    "    blocking=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sptelPO5PYjg"
   },
   "source": "## Step 4: Test the Service\n\nNow we will execute the client code, which calls our Ray Serve application to process the PDF, and then polls those task IDs for the result."
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### 4.1 Client Code to Test the Service\n\nThis is the client code to test the service."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Example client for testing asynchronous PDF processing.\n",
    "\n",
    "Demonstrates:\n",
    "1. Submitting PDF processing tasks\n",
    "2. Polling for task status\n",
    "3. Retrieving results when complete\n",
    "\"\"\"\n",
    "\n",
    "import time\n",
    "from typing import Dict, Any\n",
    "\n",
    "import requests\n",
    "\n",
    "\n",
    "class AsyncPDFClient:\n",
    "    \"\"\"Client for interacting with the async PDF processing API.\"\"\"\n",
    "\n",
    "    def __init__(self, base_url: str = \"http://localhost:8000\"):\n",
    "        \"\"\"\n",
    "        Initialize the client.\n",
    "        \"\"\"\n",
    "        self.base_url = base_url.rstrip(\"/\")\n",
    "\n",
    "    def process_pdf(self, pdf_url: str, max_summary_paragraphs: int = 3) -> str:\n",
    "        \"\"\"\n",
    "        Submit a PDF processing task.\n",
    "        \"\"\"\n",
    "        response = requests.post(\n",
    "            f\"{self.base_url}/process\",\n",
    "            json={\n",
    "                \"pdf_url\": pdf_url,\n",
    "                \"max_summary_paragraphs\": max_summary_paragraphs,\n",
    "            },\n",
    "        )\n",
    "        return response.json()[\"task_id\"]\n",
    "\n",
    "    def get_task_status(self, task_id: str) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Get the current status of a task.\n",
    "        \"\"\"\n",
    "        response = requests.get(f\"{self.base_url}/status/{task_id}\")\n",
    "        response.raise_for_status()\n",
    "        return response.json()\n",
    "\n",
    "    def wait_for_task(\n",
    "        self,\n",
    "        task_id: str,\n",
    "        poll_interval: float = 2.0,\n",
    "        timeout: float = 120.0,\n",
    "    ) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Wait for a task to complete by polling its status.\n",
    "        \"\"\"\n",
    "        start_time = time.time()\n",
    "\n",
    "        while True:\n",
    "            # Check if we've exceeded the timeout\n",
    "            if time.time() - start_time > timeout:\n",
    "                raise TimeoutError(f\"Task {task_id} timed out after {timeout}s\")\n",
    "\n",
    "            # Get current task status\n",
    "            status = self.get_task_status(task_id)\n",
    "            state = status[\"status\"]\n",
    "\n",
    "            if state == \"SUCCESS\":\n",
    "                return status\n",
    "            elif state == \"FAILURE\":\n",
    "                raise RuntimeError(f\"Task failed: {status.get('error')}\")\n",
    "            elif state in [\"PENDING\", \"STARTED\"]:\n",
    "                print(f\"  Task status: {state}, waiting...\")\n",
    "                time.sleep(poll_interval)\n",
    "            else:\n",
    "                print(f\"  Unknown status: {state}, waiting...\")\n",
    "                time.sleep(poll_interval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### 4.2 Call the Client to Make Requests to the Serve Application\n\nNow we will create the client and call the Serve application to enqueue the tasks and poll for the results."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Run example PDF processing tasks.\"\"\"\n",
    "client = AsyncPDFClient()\n",
    "\n",
    "print(\"=\" * 70, \"Asynchronous PDF Processing Example\", \"=\" * 70)\n",
    "\n",
    "# Example: Process multiple PDFs in parallel\n",
    "print(\"\\n\" + \"=\" * 70, \"Step 1: Submitting PDF processing tasks\", \"=\" * 70)\n",
    "\n",
    "pdf_urls = [\n",
    "    \"https://www.w3.org/WAI/ER/tests/xhtml/testfiles/resources/pdf/dummy.pdf\",\n",
    "    \"https://arxiv.org/pdf/1706.03762.pdf\",\n",
    "]\n",
    "\n",
    "# Submit all tasks\n",
    "task_ids = []\n",
    "for i, url in enumerate(pdf_urls, 1):\n",
    "    try:\n",
    "        task_id = client.process_pdf(url)\n",
    "        task_ids.append((task_id, url))\n",
    "        print(f\"   ✓ Task {i} submitted: {task_id}\")\n",
    "    except Exception as e:\n",
    "        print(f\"   ✗ Task {i} failed to submit: {e}\")\n",
    "\n",
    "# Wait for all tasks to complete\n",
    "print(\"\\n\" + \"=\" * 70, \"Step 2: Waiting for tasks to complete\", \"=\" * 70)\n",
    "\n",
    "for i, (task_id, url) in enumerate(task_ids, 1):\n",
    "    print(f\"\\nTask {i} ({url.split('/')[-1]}):\")\n",
    "    try:\n",
    "        result = client.wait_for_task(task_id, timeout=60.0)\n",
    "        if result[\"result\"]:\n",
    "            res = result[\"result\"]\n",
    "            print(f\"   ✓ Complete: {res['page_count']} pages, {res['word_count']} words\")\n",
    "            print(f\"   ✓ Processing time: {res['processing_time_seconds']}s\")\n",
    "    except Exception as e:\n",
    "        print(f\"   ✗ Error: {e}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70, \"Example complete!\", \"=\" * 70)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "toB6IzUzPYjh"
   },
   "source": "## Deploy to Anyscale\n\nTo deploy this application to production on Anyscale:\n\n1. Update Redis configuration in your server code with your production Redis instance\n2. Deploy using the Anyscale CLI:\n\n   ```bash\n   anyscale service deploy -f service.yaml\n   ```\n\n3. Get your service URL:\n\n   ```bash\n   anyscale service status\n   ```"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "77GW0zVFPYjh"
   },
   "source": [
    "## Learn More\n",
    "\n",
    "- [Ray Serve Documentation](https://docs.ray.io/en/latest/serve/index.html)\n",
    "- [Asynchronous Inference Guide](https://docs.ray.io/en/master/serve/asynchronous-inference.html)\n",
    "- [Celery Documentation](https://docs.celeryq.dev/)\n",
    "- [Anyscale Platform](https://docs.anyscale.com/)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}